#!/usr/bin/env node

const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');
const os = require('os');

// Configuration
const OUTPUT_DIR = path.join(__dirname, '../../test-results');
const REPORT_PATH = path.join(OUTPUT_DIR, 'neural-emotion-report.md');
const JSON_RESULTS_PATH = path.join(OUTPUT_DIR, 'neural-emotion-results.json');
const PERF_METRICS_PATH = path.join(OUTPUT_DIR, 'neural-emotion-perf-metrics.json');

// Ensure output directory exists
if (!fs.existsSync(OUTPUT_DIR)) {
  fs.mkdirSync(OUTPUT_DIR, { recursive: true });
  console.log(`Created output directory: ${OUTPUT_DIR}`);
}

/**
 * Main test run function
 */
async function runTests() {
  console.log('\n=== Neural Emotion System Integration Testing ===\n');
  
  // Capture system information
  const systemInfo = {
    os: `${os.type()} ${os.release()} ${os.arch()}`,
    cpus: os.cpus().length,
    totalMemory: `${Math.round(os.totalmem() / (1024 * 1024 * 1024))} GB`,
    freeMemory: `${Math.round(os.freemem() / (1024 * 1024 * 1024))} GB`,
    nodeVersion: process.version
  };
  
  console.log('System Information:');
  console.log(`OS: ${systemInfo.os}`);
  console.log(`CPU Cores: ${systemInfo.cpus}`);
  console.log(`Total Memory: ${systemInfo.totalMemory}`);
  console.log(`Free Memory: ${systemInfo.freeMemory}`);
  console.log(`Node Version: ${systemInfo.nodeVersion}\n`);

  // Record start time
  const startTime = Date.now();
  console.log(`Test run started at: ${new Date(startTime).toLocaleString()}\n`);
  
  // Run tests and capture output
  let testResults;
  
  try {
    // Running the integration tests with JSON reporter for capturing metrics
    console.log('Running Neural Emotion System integration tests...');
    const testOutput = execSync(
      'npx vitest run --config vitest.performance.config.ts --reporter=json tests/performance/neural_emotion_integration.test.ts', 
      { encoding: 'utf8', cwd: path.join(__dirname, '../../') }
    );
    
    // Parse JSON output
    testResults = JSON.parse(testOutput);
    
    // Save raw results to file
    fs.writeFileSync(JSON_RESULTS_PATH, JSON.stringify(testResults, null, 2));
    console.log(`Raw test results saved to: ${JSON_RESULTS_PATH}`);
  } catch (error) {
    console.error('Error running tests:', error.message);
    
    // Try to extract JSON from stderr output (Vitest still outputs JSON even on test failure)
    try {
      const errorOutput = error.stderr.toString();
      const jsonStart = errorOutput.indexOf('{');
      const jsonEnd = errorOutput.lastIndexOf('}');
      
      if (jsonStart >= 0 && jsonEnd >= 0) {
        const jsonStr = errorOutput.substring(jsonStart, jsonEnd + 1);
        testResults = JSON.parse(jsonStr);
        
        // Save raw results to file
        fs.writeFileSync(JSON_RESULTS_PATH, JSON.stringify(testResults, null, 2));
        console.log(`Raw test results saved to: ${JSON_RESULTS_PATH}`);
      } else {
        testResults = { success: false, error: error.message };
      }
    } catch (parseError) {
      console.error('Error parsing test output:', parseError.message);
      testResults = { success: false, error: error.message };
    }
  }
  
  // Record end time and calculate duration
  const endTime = Date.now();
  const duration = endTime - startTime;
  console.log(`\nTest run completed at: ${new Date(endTime).toLocaleString()}`);
  console.log(`Total duration: ${(duration / 1000).toFixed(2)} seconds\n`);
  
  // Get performance metrics
  console.log('Collecting performance metrics...');
  let perfMetrics;
  
  try {
    // Load metrics from output file (generated by the benchmark)
    const metricsPath = path.join(__dirname, '../../test-results/benchmark-metrics.json');
    if (fs.existsSync(metricsPath)) {
      const metricsData = fs.readFileSync(metricsPath, 'utf8');
      perfMetrics = JSON.parse(metricsData);
      
      // Copy to our results folder
      fs.writeFileSync(PERF_METRICS_PATH, metricsData);
      console.log(`Performance metrics saved to: ${PERF_METRICS_PATH}`);
    } else {
      console.warn('No benchmark metrics file found at:', metricsPath);
      perfMetrics = { warning: 'No metrics file generated during test' };
    }
  } catch (error) {
    console.error('Error reading performance metrics:', error.message);
    perfMetrics = { error: error.message };
  }
  
  // Generate comprehensive report
  console.log('\nGenerating comprehensive test report...');
  const report = generateTestReport(testResults, perfMetrics, {
    startTime,
    endTime,
    duration,
    systemInfo
  });
  
  fs.writeFileSync(REPORT_PATH, report);
  console.log(`\nTest report generated at: ${REPORT_PATH}`);
  
  // Final status
  if (testResults.success) {
    console.log('\n✅ Neural Emotion System integration tests PASSED');
  } else {
    console.log('\n❌ Neural Emotion System integration tests FAILED');
    console.log('See the report for details on failures and recommendations.');
  }
}

/**
 * Generate a detailed test report
 */
function generateTestReport(testResults, perfMetrics, metadata) {
  const { startTime, endTime, duration, systemInfo } = metadata;
  const { success, testFiles, stats } = testResults;
  const passRate = stats ? Math.round((stats.passed / stats.total) * 100) : 0;
  
  let report = `# Neural Emotion System Integration Test Report

## Overview

- **Test Run Date**: ${new Date(startTime).toLocaleString()}
- **Duration**: ${(duration / 1000).toFixed(2)} seconds
- **Status**: ${success ? '✅ PASSED' : '❌ FAILED'}
- **Tests**: ${stats ? `${stats.passed}/${stats.total} passed (${passRate}%)` : 'N/A'}

## System Information

- **OS**: ${systemInfo.os}
- **CPU Cores**: ${systemInfo.cpus}
- **Memory**: ${systemInfo.totalMemory} (${systemInfo.freeMemory} free)
- **Node Version**: ${systemInfo.nodeVersion}

## Test Results Summary

`;

  // Add test results details
  if (testFiles) {
    testFiles.forEach(file => {
      report += `### ${path.basename(file.name)}\n\n`;
      
      file.tasks.forEach(suite => {
        report += `#### ${suite.name}\n\n`;
        
        if (suite.tasks) {
          suite.tasks.forEach(test => {
            const status = test.result?.state === 'pass' ? '✅ PASSED' : '❌ FAILED';
            report += `- **${test.name}**: ${status} (${test.result?.duration || 'N/A'} ms)\n`;
            
            if (test.result?.state === 'fail' && test.result.errors) {
              report += '  - Errors:\n';
              test.result.errors.forEach(err => {
                report += `    - ${err.message || 'Unknown error'}\n`;
              });
            }
          });
        }
        
        report += '\n';
      });
    });
  }

  // Add performance metrics
  report += `## Performance Metrics

`;

  if (perfMetrics) {
    if (perfMetrics.latencyMeasurements) {
      // Overall latency metrics
      report += `### Latency

- **Average**: ${perfMetrics.averageLatencyMs?.toFixed(2) || 'N/A'} ms
- **Maximum**: ${perfMetrics.maxLatencyMs?.toFixed(2) || 'N/A'} ms
- **Minimum**: ${perfMetrics.minLatencyMs?.toFixed(2) || 'N/A'} ms
- **Threshold**: ${perfMetrics.latencyThresholdMs || '150'} ms
- **Status**: ${perfMetrics.passedThreshold ? '✅ Within threshold' : '❌ Exceeds threshold'}

`;

      // Detailed latency measurements
      report += `### Detailed Operation Latencies

| Operation | Duration (ms) | Status |
|-----------|---------------|--------|
`;

      perfMetrics.latencyMeasurements.forEach(measurement => {
        const status = measurement.success ? '✅' : '❌';
        report += `| ${measurement.operation} | ${measurement.durationMs.toFixed(2)} | ${status} |\n`;
      });

      report += '\n';
    }

    // Memory metrics
    if (perfMetrics.memoryGrowthMB !== undefined) {
      report += `### Memory Usage

- **Growth**: ${perfMetrics.memoryGrowthMB.toFixed(2)} MB
- **Threshold**: ${perfMetrics.memoryThresholdMB || '10'} MB
- **Status**: ${perfMetrics.memoryGrowthMB < (perfMetrics.memoryThresholdMB || 10) ? '✅ Within threshold' : '❌ Exceeds threshold'}

`;
    }

    // CPU metrics
    if (perfMetrics.cpuUtilization !== undefined) {
      report += `### CPU Utilization

- **Average**: ${perfMetrics.cpuUtilization.toFixed(2)}%

`;
    }
  } else {
    report += '⚠️ No performance metrics available\n\n';
  }

  // Add findings and recommendations
  report += `## Findings and Recommendations

`;

  // Latency findings
  if (perfMetrics?.latencyMeasurements) {
    const highLatencyOps = perfMetrics.latencyMeasurements
      .filter(m => m.durationMs > 100)
      .sort((a, b) => b.durationMs - a.durationMs);

    if (highLatencyOps.length > 0) {
      report += `### High Latency Operations

The following operations have high latency (>100ms) and may need optimization:

`;
      highLatencyOps.forEach(op => {
        report += `- **${op.operation}**: ${op.durationMs.toFixed(2)} ms\n`;
      });
      report += '\n';
    } else {
      report += '### Latency Analysis\n\nAll operations are performing within acceptable latency ranges.\n\n';
    }
  }

  // Memory findings
  if (perfMetrics?.memoryGrowthMB !== undefined) {
    if (perfMetrics.memoryGrowthMB > 5) {
      report += `### Memory Usage Concerns

Memory growth of ${perfMetrics.memoryGrowthMB.toFixed(2)} MB detected during test run. This may indicate:

- Potential memory leaks in the emotion processing pipeline
- Inefficient caching of emotion data
- Excessive object creation during rapid emotion processing

Recommendation: Profile memory usage during emotion state transitions to identify leak sources.

`;
    } else {
      report += '### Memory Usage Analysis\n\nMemory usage is stable and within acceptable limits.\n\n';
    }
  }

  // Test failure findings
  if (!success && stats && stats.failed > 0) {
    report += `### Integration Issues

${stats.failed} tests failed, indicating integration problems between components:

`;
    
    let failedTests = [];
    testFiles.forEach(file => {
      file.tasks.forEach(suite => {
        if (suite.tasks) {
          suite.tasks.forEach(test => {
            if (test.result?.state === 'fail') {
              failedTests.push({
                name: `${suite.name} > ${test.name}`,
                error: test.result.errors?.[0]?.message || 'Unknown error'
              });
            }
          });
        }
      });
    });

    failedTests.forEach(test => {
      report += `- **${test.name}**: ${test.error}\n`;
    });

    report += '\nRecommendation: Address these integration issues before proceeding to production.\n\n';
  }

  // General recommendations
  report += `## Next Steps

1. ${success ? 'Proceed with deployment preparation' : 'Fix failed integration tests'}
2. Run load testing with multiple concurrent users
3. Perform memory leak analysis with extended runtime
4. ${perfMetrics?.averageLatencyMs > 100 ? 'Optimize high-latency components' : 'Continue monitoring performance metrics'}
5. Conduct real-world user testing with actual emotional inputs

## Conclusion

${
  success && (perfMetrics?.passedThreshold ?? true)
    ? 'The Neural Emotion System successfully passed integration tests and meets performance requirements. It is ready for the next phase of testing.'
    : 'The Neural Emotion System requires additional development and optimization before proceeding to the next phase.'
}

Report generated on ${new Date().toISOString()}
`;

  return report;
}

// Run the tests
runTests().catch(error => {
  console.error('Error running neural emotion tests:', error);
  process.exit(1);
});